{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "\n",
    "def split_dataframe(df, chunk_size):\n",
    "    return [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "def process_chunk(chunk, prompt):\n",
    "    try:\n",
    "        chunk['ai_output'] = chunk['description'].apply(transform, prompt=prompt)\n",
    "        return chunk\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "# Split DataFrame\n",
    "chunks = split_dataframe(df_des, 20)\n",
    "processed_chunks = []\n",
    "\n",
    "# Process Chunks with Timeout\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            print(f\"Processing chunk {i + 1}/{len(chunks)}...\")\n",
    "            future = executor.submit(process_chunk, chunk, prompt)\n",
    "            processed_chunks.append(future.result(timeout=60))  # Timeout for each chunk\n",
    "        except TimeoutError:\n",
    "            print(f\"Chunk {i + 1} timed out.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in chunk {i + 1}: {e}\")\n",
    "\n",
    "# Combine Processed Chunks\n",
    "processed_chunks = [chunk for chunk in processed_chunks if chunk is not None]\n",
    "result_df = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "# Save Final Result\n",
    "result_df.to_csv(\"final_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
