{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using AI to Transform Job Descriptions into Structured Data\n",
    "The description section of a job posting contains critical information but is challenging to process due to its unstructured nature. Leveraging OpenAI's API, I automate the extraction of key details from hundreds of job descriptions in minutes, converting them into structured, machine-readable formats. This significantly reduces processing time and effort. Yet, there are a lot of pitfalls when using AI for large scale information processing. Prompt engineering is vital for effectively process the data.\n",
    "\n",
    "### Prompt Engineering\n",
    "**Effective prompt** engineering ensures consistent and accurate AI outputs. Key techniques used in this project include:\n",
    "1. **Clarity and Context**: Clearly request specific information, such as extracting details from the job description column.\n",
    "2. **Formatting Requests**: Instruct ChatGPT to output data as a Python dictionary, ensuring consistency and facilitating subsequent processing.\n",
    "3. **Iterative Refinement**: Generate small sample outputs, identify issues, and refine the prompt to address inconsistencies.\n",
    "4. **Explicit Constraints**: Limit output to concise key terms, such as restricting skills to one or two words, to ensure usability.  \n",
    "\n",
    "This structured approach maximizes efficiency and reliability when processing natural language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the prompt from file\n",
    "with open('prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# call openai api to convert job description to a dictionary of key informations\n",
    "df_ai_dict = df['description'].apply(transform, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_dict.to_csv('ai_generated_dict.csv')\n",
    "df_ai_dict = pd.read_csv('ai_generated_dict.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each key-value pairsin ai generated dictionary to new columns\n",
    "df_ai_cols = dict_to_cols(df_ai_dict, 'description')\n",
    "df_ai_cols.to_csv('ai_generated_cols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ai generated cols into the orginal dataframe\n",
    "df0 = df0.reset_index(drop=True)\n",
    "df_ai_cols = df_ai_cols.reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df0, df_ai_cols], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a new file\n",
    "df.to_csv('complete1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
