{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import time as time\n",
    "# AI\n",
    "import tiktoken\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt api\n",
    "load_dotenv('keys.env')\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for GPT model\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "# Parameters\n",
    "max_tokens_per_request = 16384  # Max tokens allowed by the model\n",
    "max_tokens_input = max_tokens_per_request // 2  # Reserve half for input\n",
    "\n",
    "# Function to process a batch\n",
    "def process_batch(json):\n",
    "    print(json)\n",
    "    # Create a prompt\n",
    "    prompt = f\"\"\"\n",
    "                Here is a JSON data: \n",
    "                {json}\n",
    "                \n",
    "                Please process it according to the following instructions:\n",
    "\n",
    "                1. Add the following new keys to each object in the dataset:\n",
    "                - \"skills\": A list of strings extracted from the \"description\", each skill is a one or two word keywords.\n",
    "                - \"min_year_of_experience\": An integer extracted from the \"description\" or left blank if not found.\n",
    "                - \"preferred_year_of_experience\": An integer extracted from the \"description\" or left blank if not found.\n",
    "                - \"salary_low\": An integer. If the key \"salary\" in the original dataset has a value, use it; otherwise, extract the information from the \"description\". If not found, leave it blank.\n",
    "                - \"salary_high\": An integer. Process it similarly to \"salary_low\".\n",
    "                - \"avg_salary\": An integer calculated as the average of \"salary_low\" and \"salary_high\" (if both are available; otherwise, leave it blank).\n",
    "                - \"location_st\": A string standardized from the \"location\" field in the original dataset. Use the format \"City, State\". For example:\n",
    "                    - \"New York Metropolitan Area\" → \"New York, NY\".\n",
    "                    - \"California, United States\" → \"None, CA\".\n",
    "                    - If the original value is simply \"United States\", leave it blank.\n",
    "                - \"min_degree\": A string extracted from the \"description\" or left blank if not found.\n",
    "                - \"preferred_degree\": A string extracted from the \"description\" or left blank if not found.\n",
    "\n",
    "                2. Extract all additional information from the \"description\" field if not directly available in other fields.\n",
    "\n",
    "                3. Ensure all new keys are included in the output, even if their values are blank.\n",
    "\n",
    "                print the new JSON dataset without the \"description\" and without any characters that is not part of a JSON data structure.\n",
    "            \"\"\"\n",
    "    \n",
    "    # Call OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Update to a valid model name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract and parse the response\n",
    "    content = response.choices[0].message.content\n",
    "    print(content)\n",
    "    # content = str(response.choices[0].message.content)\n",
    "    try:\n",
    "        return pd.read_csv(content)  # Parse JSON safely\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing API response: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function for batch processing\n",
    "def batch_process(df):\n",
    "    results = []\n",
    "    current_batch = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert row to JSON\n",
    "        row_json = row.to_dict()\n",
    "        row_tokens = len(tokenizer.encode(json.dumps(row_json)))\n",
    "        \n",
    "        # Check if adding the current row exceeds the token limit\n",
    "        if current_tokens + row_tokens > max_tokens_input:\n",
    "            # Process the current batch\n",
    "            batch_json = json.dumps(current_batch)  # Convert to JSON array\n",
    "            print(f\"Processing batch with {len(current_batch)} rows at index {index}...\")\n",
    "            try:\n",
    "                result_df = process_batch(batch_json)\n",
    "                results.append(result_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "            \n",
    "            # Reset for the next batch\n",
    "            current_batch = []\n",
    "            current_tokens = 0\n",
    "        \n",
    "        # Add row to the current batch\n",
    "        current_batch.append(row_json)\n",
    "        current_tokens += row_tokens\n",
    "\n",
    "    # Process the last batch\n",
    "    if current_batch:\n",
    "        batch_json = json.dumps(current_batch)\n",
    "        print(f\"Processing final batch with {len(current_batch)} rows...\")\n",
    "        try:\n",
    "            result_df = process_batch(batch_json)\n",
    "            results.append(result_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing final batch: {e}\")\n",
    "\n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_df = pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    new_cols = ['skills', 'location_st', 'salary_low', 'salary_high', 'min_year_of_experience', 'preferred_year_of_experience', ]\n",
    "# this function call the openai api, input the prompt and return the response in a string\n",
    "# string is cleaned to only return the python dictionary\n",
    "def transform(row):\n",
    "    json_data = row.to_json()\n",
    "    print(json_data)\n",
    "    # concat directions and the input text\n",
    "    prompt = f\"\"\"\n",
    "                Here is a JSON data: \n",
    "                {json_data}\n",
    "                \n",
    "                Add values to the following keys:\n",
    "                - \"skills\": A list of strings extracted from the \"description\", each skill is a one or two word keywords.\n",
    "                - \"min year of experience\": An integer extracted from the \"description\" or left blank if not found.\n",
    "                - \"preferred_year_of_experience\": An integer extracted from the \"description\" or left blank if not found.\n",
    "                - \"salary low\": An integer. If the key \"salary\" in the original dataset has a value, use it; otherwise, extract the information from the \"description\". If not found, leave it blank.\n",
    "                - \"salary high\": An integer. Process it similarly to \"salary_low\".\n",
    "                - \"location_st\": A string standardized from the \"location\" key. Use the format \"City, State\". State must be two letter. For example:\n",
    "                    - \"New York Metropolitan Area\" → \"New York, NY\".\n",
    "                    - \"California, United States\" → \"None, CA\".\n",
    "                    - If the original value is simply \"United States\", leave it blank.\n",
    "                - \"min_degree\": A string extracted from the \"description\" or left blank if not found.\n",
    "                - \"preferred_degree\": A string extracted from the \"description\" or left blank if not found.\n",
    "\n",
    "                output the new JSON object minus \"description\".\n",
    "            \"\"\"\n",
    "    # print(prompt)\n",
    "    retry = 0\n",
    "\n",
    "    # call api\n",
    "    while retry <= 10:\n",
    "        print(f\"Start API call at {datetime.now()}\")\n",
    "        try:\n",
    "            # Call API\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                timeout=60\n",
    "            )\n",
    "            content = str(response.choices[0].message.content)\n",
    "\n",
    "            # Handle 'null' and 'None' by replacing them with actual Python None\n",
    "            content = content.replace(\"null\", \"None\")\n",
    "\n",
    "            # Extract JSON-like content between first `{` and last `}`\n",
    "            start = content.find('{')\n",
    "            end = content.rfind('}')\n",
    "            if start != -1 and end != -1:\n",
    "                content = content[start:end+1]\n",
    "                # make sure it's a valid dictionary format that can be converted using eval\n",
    "                row = pd.DataFrame([[content]], columns=['test_content'])\n",
    "                row = row['test_content'].apply(eval)\n",
    "                print(f\"retrieved dictionary at {datetime.now()}\")\n",
    "                return content\n",
    "\n",
    "            else:\n",
    "                print(f\"No valid JSON-like content found in response at {datetime.now()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call or processing: {e}\")\n",
    "        \n",
    "        retry += 1\n",
    "        print(f\"Retrying {retry}...\")\n",
    "        time.sleep(4)\n",
    "\n",
    "    print(\"Failed to retrieve dictionary after maximum retries.\")\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
